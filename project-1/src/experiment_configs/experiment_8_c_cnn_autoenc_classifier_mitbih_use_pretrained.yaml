pipeline_class: "ExperimentPipelineForClassifier" 
experiment_metadata:
  description: "CnnPretrainEncoderWithTrainableClassifierHead"
  tag: "CnnPretrainEncoderWithTrainableClassifierHead-MITBIH-FrozenEncoder-Encoder-Frozen"
dataloader_class_name: "BalancedMITBIHDataLoader" #"BalancedMITBIHDataLoader"
val_split: 0.2 # validation split ratio
model_class_name: CnnPretrainEncoderWithTrainableClassifierHead #"CnnEncoder" #"CnnPretrainEncoderWithTrainableClassifierHead"
load_from_checkpoint: true # load the weights (pretrained somehow)
checkpoint_path: "saved_models/2022-03-27_190521__CnnEncoderDecoder_Mitbih/best_model.ckpt"
cost_function_class_name: "CrossEntropyLoss"
trainer_class_name: "CnnTrainer"
num_epochs: 50
batch_size: 32
learning_rate: 0.001
weight_decay: 0.0000001
logdir: "runs"
batch_log_frequency: 1 # Print log after after these many batches
tensorboard_log_frequency: 100 # Log scalars after these many batches
test_batch_size: 100
scheduler: "ReduceLROnPlateau"
